# services/ui/pages/credit_appraisal.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŒ OpenSource AI Agent Library + Credit Appraisal PoC by Dzoan
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from __future__ import annotations
import os
import re
import io
import json
from datetime import datetime, timezone
from typing import Optional, Dict, List, Any
import pandas as pd
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timezone
from pandas import json_normalize  # ADD
import random, hashlib, requests, shutil, base64




# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PAGE CONFIG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Credit Appraisal Agent", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SESSION STATE SHORTCUT + DEFAULTS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ss = st.session_state

defaults = {
    "credit_stage": "login",
    "credit_logged_in": False,
    "ui_theme": "light",
    "credit_user": {"name": "Guest", "email": None},
}
for k, v in defaults.items():
    if k not in ss:
        ss[k] = v



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SESSION STATE INIT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "credit_stage" not in st.session_state:
    st.session_state.credit_stage = "login"
if "credit_logged_in" not in st.session_state:
    st.session_state.credit_logged_in = False


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# THEME SWITCHER (identical to asset_appraisal)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "ui_theme" not in st.session_state:
    st.session_state["ui_theme"] = "light"

def apply_theme(theme: str = "light"):
    if theme == "light":
        bg, text, sub, accent = "#ffffff", "#0f172a", "#334155", "#2563eb"
    else:
        bg, text, sub, accent = "#0E1117", "#f1f5f9", "#93a4b8", "#3b82f6"
    st.markdown(f"""
    <style>
      .stApp {{background:{bg}!important;color:{text}!important;}}
      .stCaption,p,li {{color:{sub}!important;}}
      .stButton>button {{background:{accent}!important;color:white!important;}}
    </style>
    """, unsafe_allow_html=True)

apply_theme(st.session_state["ui_theme"])




# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GLOBAL CONFIG (directories + API)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.expanduser("~/credit-appraisal-agent-poc/services/ui/pages")
LANDING_IMG_DIR = os.path.join(BASE_DIR, "landing_images")
RUNS_DIR = os.path.join(BASE_DIR, ".tmp_runs")
TMP_FEEDBACK_DIR = os.path.join(BASE_DIR, ".tmp_feedback")

for d in (LANDING_IMG_DIR, RUNS_DIR, TMP_FEEDBACK_DIR):
    os.makedirs(d, exist_ok=True)

API_URL = os.getenv("API_URL", "http://localhost:8090")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GLOBAL UTILS (from asset agent)


def extract_run_id(obj) -> Optional[str]:
    if isinstance(obj, dict):
        if isinstance(obj.get("run_id"), str):
            return obj["run_id"]
        res = obj.get("result")
        if isinstance(res, dict) and isinstance(res.get("run_id"), str):
            return res["run_id"]
    if isinstance(obj, list):
        for it in obj:
            rid = extract_run_id(it)
            if rid:
                return rid
    return None

def json_to_dataframe(payload) -> Optional[pd.DataFrame]:
    if isinstance(payload, dict):
        res = payload.get("result") or {}
        if isinstance(res, list):
            return pd.DataFrame(res)
        if isinstance(res, dict):
            return pd.json_normalize(res)
    if isinstance(payload, list):
        return pd.DataFrame(payload)
    return None

def _extract_run_fields(raw_json):
    run_id = extract_run_id(raw_json)
    payload = raw_json if isinstance(raw_json, dict) else {"result": raw_json}
    return run_id, payload

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GLOBAL UTILITIES (extended)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_run_id(obj) -> str | None:  # ADD
    """Find run_id in common places regardless of payload shape."""
    if isinstance(obj, dict):
        if isinstance(obj.get("run_id"), str):
            return obj["run_id"]
        res = obj.get("result")
        if isinstance(res, dict) and isinstance(res.get("run_id"), str):
            return res["run_id"]
        for key in ("summary", "meta", "data"):
            sub = obj.get(key)
            if isinstance(sub, dict) and isinstance(sub.get("run_id"), str):
                return sub["run_id"]
    if isinstance(obj, list):
        for it in obj:
            if isinstance(it, dict):
                rid = extract_run_id(it)
                if rid:
                    return rid
    return None

def json_to_dataframe(payload) -> pd.DataFrame | None:  # ADD
    """
    Convert arbitrary API JSON into a DataFrame.
    Tries common shapes first, then falls back to json_normalize.
    """
    # Prefer artifacts.merged_csv if present and readable
    if isinstance(payload, dict):
        res = payload.get("result") or {}
        artifacts = res.get("artifacts") or {}
        merged_csv = artifacts.get("merged_csv")
        if isinstance(merged_csv, str) and os.path.exists(merged_csv):
            try:
                return pd.read_csv(merged_csv)
            except Exception:
                pass

        # Embedded tabular data
        merged_df = res.get("merged_df")
        if merged_df is not None:
            try:
                return pd.DataFrame(merged_df)
            except Exception:
                pass

        # Generic result â†’ DF
        if isinstance(res, list):
            try:
                return pd.DataFrame(res)
            except Exception:
                try:
                    return json_normalize(res)
                except Exception:
                    pass
        if isinstance(res, dict) and res:
            try:
                return json_normalize(res)
            except Exception:
                pass

        # Top-level dict
        try:
            return json_normalize(payload)
        except Exception:
            pass

    # Top-level list
    if isinstance(payload, list):
        try:
            return pd.DataFrame(payload)
        except Exception:
            try:
                return json_normalize(payload)
            except Exception:
                pass
    return None

def _extract_run_fields(raw_json):  # ADD
    """
    Return (run_id, normalized_payload_dict).
    Ensures downstream code always receives a dict-like 'payload'.
    """
    run_id = extract_run_id(raw_json)

    # Normalize to dict payload so later code can access keys safely
    payload = raw_json
    if not isinstance(payload, dict):
        if isinstance(payload, list):
            first_dict = next((x for x in payload if isinstance(x, dict)), None)
            payload = first_dict if first_dict is not None else {"result": raw_json}
        else:
            payload = {"result": raw_json}
    return run_id, payload



def quick_synth(n: int = 20) -> pd.DataFrame:
    now = datetime.now(timezone.utc)
    return pd.DataFrame([
        {
            "application_id": f"APP_{now.strftime('%H%M%S')}_{i:04d}",
            "asset_id": f"A{now.strftime('%M%S')}{i:04d}",
            "customer_name": f"Customer {i}",
            "credit_score": random.randint(550, 820),
            "loan_amount": random.randint(5000, 50000),
            "income": random.randint(1000, 10000),
            "city": random.choice(["HCMC", "Hanoi", "Da Nang", "Can Tho"]),
            "status": random.choice(["pending", "approved", "rejected"]),
        }
        for i in range(n)
    ])

def sha1_of_filelike(fobj) -> str:
    pos = fobj.tell() if hasattr(fobj, "tell") else None
    fobj.seek(0)
    h = hashlib.sha1()
    for chunk in iter(lambda: fobj.read(8192), b""):
        if isinstance(chunk, str):
            chunk = chunk.encode("utf-8")
        h.update(chunk)
    if pos is not None:
        fobj.seek(pos)
    return h.hexdigest()

def save_to_runs(df: pd.DataFrame, name: str) -> str:
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    path = os.path.join(RUNS_DIR, f"{name}_{ts}.csv")
    df.to_csv(path, index=False)
    return path



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HELPERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _extract_run_fields(res_json):
    """
    Return (run_id, result_dict) from API responses that may be dicts or lists.
    """
    run_id = None
    result_obj = {}

    if isinstance(res_json, dict):
        run_id = (
            res_json.get("run_id")
            or res_json.get("id")
            or (res_json.get("data") or {}).get("run_id")
        )
        result_obj = (
            res_json.get("result")
            or (res_json.get("data") or {}).get("result")
            or {}
        )

    elif isinstance(res_json, list):
        # Find first dict item that contains identifiers/results
        for item in res_json:
            if isinstance(item, dict):
                if not run_id:
                    run_id = item.get("run_id") or item.get("id")
                if not result_obj:
                    result_obj = item.get("result") or {}
                if run_id and result_obj != {}:
                    break
        # If still nothing and list[0] is a dict, use it as best-effort
        if not run_id and res_json and isinstance(res_json[0], dict):
            run_id = res_json[0].get("run_id") or res_json[0].get("id")
            result_obj = res_json[0].get("result") or {}

    # Ensure result is a dict
    if not isinstance(result_obj, dict):
        result_obj = {"value": result_obj}

    return run_id, result_obj


def _clear_qp():
    """Clear query params (modern Streamlit API)."""
    try:
        st.query_params.clear()
    except Exception:
        pass


def load_image(base: str) -> Optional[str]:
    for ext in [".png", ".jpg", ".jpeg", ".webp", ".gif", ".svg"]:
        p = os.path.join(LANDING_IMG_DIR, f"{base}{ext}")
        if os.path.exists(p):
            return p
    return None


def save_uploaded_image(uploaded_file, base: str):
    if not uploaded_file:
        return None
    ext = os.path.splitext(uploaded_file.name)[1].lower() or ".png"
    dest = os.path.join(LANDING_IMG_DIR, f"{base}{ext}")
    with open(dest, "wb") as f:
        f.write(uploaded_file.getvalue())
    return dest


def render_image_tag(agent_id: str, industry: str, emoji_fallback: str) -> str:
    base = agent_id.lower().replace(" ", "_")
    img_path = load_image(base) or load_image(industry.replace(" ", "_"))
    if img_path:
        return (
            f'<img src="file://{img_path}" '
            f'style="width:48px;height:48px;border-radius:10px;object-fit:cover;">'
        )
    return f'<div style="font-size:32px;">{emoji_fallback}</div>'


def render_nav_bar_app():
  c1, c2 = st.columns([1, 1])
  with c1:
    if st.button("ğŸ  Back to Home"):
      st.switch_page("../../landing_page.py")
  with c2:
    is_dark = (ss.get("ui_theme","dark") == "dark")
    new = st.toggle("ğŸŒ™ Dark mode", value=is_dark)
    if new != is_dark:
      ss["ui_theme"] = "dark" if new else "light"
      apply_theme(ss["ui_theme"])
  st.markdown("---")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# QUERY PARAM ROUTING (modern API)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    qp = st.query_params
except Exception:
    qp = {}

# if "stage" in qp:
#     target = qp["stage"]
#     # Add "asset_agent" here so it's recognized
#     if target in {"landing", "agents", "login", "credit_agent", "asset_agent"} and st.session_state.stage != target:
#         st.session_state.stage = target
#         _clear_qp()
#         st.rerun()

if "stage" in qp:
    target = qp["stage"]
    if target in {"landing", "agents", "login", "credit_agent", "asset_agent"}:
        ss["credit_stage"] = target
        _clear_qp()
        st.rerun()


# Handle direct launch requests for specific agents
if "launch" in qp or "agent" in qp:
    agent = qp.get("agent", [""])[0] if isinstance(qp.get("agent"), list) else qp.get("agent", "")
    if agent == "credit":
        st.session_state.stage = "login"
    elif agent == "asset":
        st.session_state.stage = "asset_agent"
    _clear_qp()
    st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GLOBAL UTILS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


BANNED_NAMES = {"race", "gender", "religion", "ethnicity", "ssn", "national_id"}
PII_COLS = {"customer_name", "name", "email", "phone", "address", "ssn", "national_id", "dob"}

EMAIL_RE = re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}")
PHONE_RE = re.compile(r"\+?\d[\d\-\s]{6,}\d")

def dedupe_columns(df: pd.DataFrame) -> pd.DataFrame:
    return df.loc[:, ~df.columns.duplicated(keep="last")]

def scrub_text_pii(s):
    if not isinstance(s, str):
        return s
    s = EMAIL_RE.sub("", s)
    s = PHONE_RE.sub("", s)
    return s.strip()

def drop_pii_columns(df: pd.DataFrame):
    original_cols = list(df.columns)
    keep_cols = [c for c in original_cols if all(k not in c.lower() for k in PII_COLS)]
    dropped = [c for c in original_cols if c not in keep_cols]
    out = df[keep_cols].copy()
    for c in out.select_dtypes(include="object"):
        out[c] = out[c].apply(scrub_text_pii)
    return dedupe_columns(out), dropped

def strip_policy_banned(df: pd.DataFrame) -> pd.DataFrame:
    keep = []
    for c in df.columns:
        cl = c.lower()
        if cl in BANNED_NAMES:
            continue
        keep.append(c)
    return df[keep]

def append_user_info(df: pd.DataFrame) -> pd.DataFrame:
    meta = st.session_state["user_info"]
    out = df.copy()
    out["session_user_name"] = meta["name"]
    out["session_user_email"] = meta["email"]
    out["session_flagged"] = meta["flagged"]
    out["created_at"] = meta["timestamp"]
    return dedupe_columns(out)

def save_to_runs(df: pd.DataFrame, prefix: str) -> str:
    #ts = datetime.now(timezone.utc).strftime("%Y-%m-%d_%H-%M")
    ts = datetime.now(timezone.utc).strftime("%Y-%m-%d_%H-%M")
    flag_suffix = "_FLAGGED" if st.session_state["user_info"]["flagged"] else ""
    fname = f"{prefix}_{ts}{flag_suffix}.csv"
    fpath = os.path.join(RUNS_DIR, fname)
    dedupe_columns(df).to_csv(fpath, index=False)
    return fpath

def try_json(x):
    if isinstance(x, (dict, list)):
        return x
    if not isinstance(x, str):
        return None
    try:
        return json.loads(x)
    except Exception:
        return None

def _safe_json(x):
    if isinstance(x, dict):
        return x
    if isinstance(x, str) and x.strip():
        try:
            return json.loads(x)
        except Exception:
            return {}
    return {}

def fmt_currency_label(base: str) -> str:
    sym = st.session_state.get("currency_symbol", "")
    return f"{base} ({sym})" if sym else base

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CURRENCY CATALOG

CURRENCY_OPTIONS = {
    # code: (label, symbol, fx to apply on USD-like base generated numbers)
    "USD": ("USD $", "$", 1.0),
    "EUR": ("EUR â‚¬", "â‚¬", 0.93),
    "GBP": ("GBP Â£", "Â£", 0.80),
    "JPY": ("JPY Â¥", "Â¥", 150.0),
    "VND": ("VND â‚«", "â‚«", 24000.0),
}

def set_currency_defaults():
    if "currency_code" not in st.session_state:
        st.session_state["currency_code"] = "USD"
    label, symbol, fx = CURRENCY_OPTIONS[st.session_state["currency_code"]]
    st.session_state["currency_label"] = label
    st.session_state["currency_symbol"] = symbol
    st.session_state["currency_fx"] = fx

set_currency_defaults()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DASHBOARD HELPERS (Plotly, dark theme)

def _kpi_card(label: str, value: str, sublabel: str | None = None):
    st.markdown(
        f"""
        <div style="background:#0e1117;border:1px solid #2a2f3e;border-radius:12px;padding:14px 16px;margin-bottom:10px;">
          <div style="font-size:12px;color:#9aa4b2;text-transform:uppercase;letter-spacing:.06em;">{label}</div>
          <div style="font-size:28px;font-weight:700;color:#e6edf3;line-height:1.1;margin-top:2px;">{value}</div>
          {f'<div style="font-size:12px;color:#9aa4b2;margin-top:6px;">{sublabel}</div>' if sublabel else ''}
        </div>
        """,
        unsafe_allow_html=True,
    )

def render_credit_dashboard(df: pd.DataFrame, currency_symbol: str = ""):
    """
    Renders the whole dashboard (TOP-10s â†’ Opportunities â†’ KPIs & pies/bars â†’ Mix table).
    Keeps decision filter in the table only.
    """
    if df is None or df.empty:
        st.info("No data to visualize yet.")
        return

    cols = df.columns

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TOP 10s FIRST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("## ğŸ” Top 10 Snapshot")

    # Top 10 loans approved
    if {"decision", "loan_amount", "application_id"} <= set(cols):
        top_approved = df[df["decision"].astype(str).str.lower() == "approved"].copy()
        if not top_approved.empty:
            top_approved = top_approved.sort_values("loan_amount", ascending=False).head(10)
            fig = px.bar(
                top_approved,
                x="loan_amount",
                y="application_id",
                orientation="h",
                title="Top 10 Approved Loans",
                labels={"loan_amount": f"Loan Amount {currency_symbol}", "application_id": "Application"},
            )
            fig.update_layout(margin=dict(l=10, r=10, t=50, b=10), height=420, template="plotly_dark")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No approved loans available to show top 10.")

    # Top 10 collateral types by average value
    if {"collateral_type", "collateral_value"} <= set(cols):
        cprof = df.groupby("collateral_type", dropna=False).agg(
            avg_value=("collateral_value", "mean"),
            cnt=("collateral_type", "count")
        ).reset_index()
        if not cprof.empty:
            cprof = cprof.sort_values("avg_value", ascending=False).head(10)
            fig = px.bar(
                cprof,
                x="avg_value",
                y="collateral_type",
                orientation="h",
                title="Top 10 Collateral Types (Avg Value)",
                labels={"avg_value": f"Avg Value {currency_symbol}", "collateral_type": "Collateral Type"},
                hover_data=["cnt"]
            )
            fig.update_layout(margin=dict(l=10, r=10, t=50, b=10), height=420, template="plotly_dark")
            st.plotly_chart(fig, use_container_width=True)

    # Top 10 reasons for denial (from rule_reasons False flags)
    if "rule_reasons" in cols and "decision" in cols:
        denied = df[df["decision"].astype(str).str.lower() == "denied"].copy()
        reasons_count = {}
        for _, r in denied.iterrows():
            rr = _safe_json(r.get("rule_reasons"))
            if isinstance(rr, dict):
                for k, v in rr.items():
                    if v is False:
                        reasons_count[k] = reasons_count.get(k, 0) + 1
        if reasons_count:
            items = pd.DataFrame(sorted(reasons_count.items(), key=lambda x: x[1], reverse=True),
                                 columns=["reason", "count"]).head(10)
            fig = px.bar(
                items, x="count", y="reason", orientation="h",
                title="Top 10 Reasons for Denial",
                labels={"count": "Count", "reason": "Rule"},
            )
            fig.update_layout(margin=dict(l=10, r=10, t=50, b=10), height=420, template="plotly_dark")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No denial reasons detected.")

    # Top 10 loan officer performance (approval rate) if officer column present
    officer_col = None
    for guess in ("loan_officer", "officer", "reviewed_by", "session_user_name"):
        if guess in cols:
            officer_col = guess
            break
    if officer_col and "decision" in cols:
        perf = (
            df.assign(is_approved=(df["decision"].astype(str).str.lower() == "approved").astype(int))
              .groupby(officer_col, dropna=False)["is_approved"]
              .agg(approved_rate="mean", n="count")
              .reset_index()
        )
        if not perf.empty:
            perf["approved_rate_pct"] = (perf["approved_rate"] * 100).round(1)
            perf = perf.sort_values(["approved_rate_pct", "n"], ascending=[False, False]).head(10)
            fig = px.bar(
                perf, x="approved_rate_pct", y=officer_col, orientation="h",
                title="Top 10 Loan Officer Approval Rate (this batch)",
                labels={"approved_rate_pct": "Approval Rate (%)", officer_col: "Officer"},
                hover_data=["n"]
            )
            fig.update_layout(margin=dict(l=10, r=10, t=50, b=10), height=420, template="plotly_dark")
            st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ OPPORTUNITIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("## ğŸ’¡ Opportunities")

    # Short-term loan opportunities (simple heuristic)
    opp_rows = []
    if {"income", "loan_amount"}.issubset(cols):
        term_col = "loan_term_months" if "loan_term_months" in cols else ("loan_duration_months" if "loan_duration_months" in cols else None)
        if term_col:
            for _, r in df.iterrows():
                inc = float(r.get("income", 0) or 0)
                amt = float(r.get("loan_amount", 0) or 0)
                term = int(r.get(term_col, 0) or 0)
                dti = float(r.get("DTI", 0) or 0)
                if (term >= 36) and (amt <= inc * 0.8) and (dti <= 0.45):
                    opp_rows.append({
                        "application_id": r.get("application_id"),
                        "suggested_term": 24,
                        "loan_amount": amt,
                        "income": inc,
                        "DTI": dti,
                        "note": "Candidate for short-term plan (<=24m) based on affordability."
                    })
    if opp_rows:
        st.markdown("#### ğŸ“ Short-Term Loan Candidates")
        st.dataframe(pd.DataFrame(opp_rows).head(25), use_container_width=True, height=320)
    else:
        st.info("No short-term loan candidates identified in this batch.")

    st.markdown("#### ğŸ” Buyback / Consolidation Beneficiaries")
    candidates = []
    need = {"decision", "existing_debt", "loan_amount", "DTI"}
    if need <= set(cols):
        for _, r in df.iterrows():
            dec = str(r.get("decision", "")).lower()
            debt = float(r.get("existing_debt", 0) or 0)
            loan = float(r.get("loan_amount", 0) or 0)
            dti = float(r.get("DTI", 0) or 0)
            proposal = _safe_json(r.get("proposed_consolidation_loan", {}))
            has_bb = bool(proposal)

            if dec == "denied" or dti > 0.45 or debt > loan:
                benefit_score = round((debt / (loan + 1e-6)) * 0.4 + dti * 0.6, 2)
                candidates.append({
                    "application_id": r.get("application_id"),
                    "customer_type": r.get("customer_type"),
                    "existing_debt": debt,
                    "loan_amount": loan,
                    "DTI": dti,
                    "collateral_type": r.get("collateral_type"),
                    "buyback_proposed": has_bb,
                    "buyback_amount": proposal.get("buyback_amount") if has_bb else None,
                    "benefit_score": benefit_score,
                    "note": proposal.get("note") if has_bb else None
                })
    if candidates:
        cand_df = pd.DataFrame(candidates).sort_values("benefit_score", ascending=False)
        st.dataframe(cand_df.head(25), use_container_width=True, height=380)
    else:
        st.info("No additional buyback beneficiaries identified.")

    st.markdown("---")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PORTFOLIO KPIs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("## ğŸ“ˆ Portfolio Snapshot")
    c1, c2, c3, c4 = st.columns(4)

    # Approval rate
    if "decision" in cols:
        total = len(df)
        approved = int((df["decision"].astype(str).str.lower() == "approved").sum())
        rate = (approved / total * 100) if total else 0.0
        with c1: _kpi_card("Approval Rate", f"{rate:.1f}%", f"{approved} of {total}")

    # Avg approved loan amount
    if {"decision", "loan_amount"} <= set(cols):
        ap = df[df["decision"].astype(str).str.lower() == "approved"]["loan_amount"]
        avg_amt = ap.mean() if len(ap) else 0.0
        with c2: _kpi_card("Avg Approved Amount", f"{currency_symbol}{avg_amt:,.0f}")

    # Decision time (if present)
    if {"created_at", "decision_at"} <= set(cols):
        try:
            t = (pd.to_datetime(df["decision_at"]) - pd.to_datetime(df["created_at"])).dt.total_seconds() / 60.0
            avg_min = float(t.mean())
            with c3: _kpi_card("Avg Decision Time", f"{avg_min:.1f} min")
        except Exception:
            with c3: _kpi_card("Avg Decision Time", "â€”")

    # Non-bank share
    if "customer_type" in cols:
        nb = int((df["customer_type"].astype(str).str.lower() == "non-bank").sum())
        total = len(df)
        share = (nb / total * 100) if total else 0.0
        with c4: _kpi_card("Non-bank Share", f"{share:.1f}%", f"{nb} of {total}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ COMPOSITION & RISK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("## ğŸ§­ Composition & Risk")

    # Approval vs Denial (pie)
    if "decision" in cols:
        pie_df = df["decision"].value_counts().rename_axis("Decision").reset_index(name="Count")
        fig = px.pie(pie_df, names="Decision", values="Count", title="Decision Mix")
        fig.update_layout(margin=dict(l=10, r=10, t=60, b=10), height=360, template="plotly_dark")
        st.plotly_chart(fig, use_container_width=True)

    # Avg DTI / LTV by decision (grouped bars)
    have_dti = "DTI" in cols
    have_ltv = "LTV" in cols
    if "decision" in cols and (have_dti or have_ltv):
        agg_map = {}
        if have_dti: agg_map["avg_DTI"] = ("DTI", "mean")
        if have_ltv: agg_map["avg_LTV"] = ("LTV", "mean")
        grp = df.groupby("decision").agg(**agg_map).reset_index()
        melted = grp.melt(id_vars=["decision"], var_name="metric", value_name="value")
        fig = px.bar(melted, x="decision", y="value", color="metric",
                     barmode="group", title="Average DTI / LTV by Decision")
        fig.update_layout(margin=dict(l=10, r=10, t=60, b=10), height=360, template="plotly_dark")
        st.plotly_chart(fig, use_container_width=True)

    # Loan term mix (stacked)
    term_col = "loan_term_months" if "loan_term_months" in cols else ("loan_duration_months" if "loan_duration_months" in cols else None)
    if term_col and "decision" in cols:
        mix = df.groupby([term_col, "decision"]).size().reset_index(name="count")
        fig = px.bar(
            mix, x=term_col, y="count", color="decision", title="Loan Term Mix",
            labels={term_col: "Term (months)", "count": "Count"}, barmode="stack"
        )
        fig.update_layout(margin=dict(l=10, r=10, t=60, b=10), height=360, template="plotly_dark")
        st.plotly_chart(fig, use_container_width=True)

    # Collateral avg value by type (bar)
    if {"collateral_type", "collateral_value"} <= set(cols):
        cprof = df.groupby("collateral_type").agg(
            avg_col=("collateral_value", "mean"),
            cnt=("collateral_type", "count")
        ).reset_index()
        fig = px.bar(
            cprof.sort_values("avg_col", ascending=False),
            x="collateral_type", y="avg_col",
            title=f"Avg Collateral Value by Type ({currency_symbol})",
            hover_data=["cnt"]
        )
        fig.update_layout(margin=dict(l=10, r=10, t=60, b=10), height=360, template="plotly_dark")
        st.plotly_chart(fig, use_container_width=True)

    # Top proposed plans (horizontal bar)
    if "proposed_loan_option" in cols:
        plans = df["proposed_loan_option"].dropna().astype(str)
        if len(plans) > 0:
            plan_types = []
            for s in plans:
                p = _safe_json(s)
                plan_types.append(p.get("type") if isinstance(p, dict) and "type" in p else s)
            plan_df = pd.Series(plan_types).value_counts().head(10).rename_axis("plan").reset_index(name="count")
            fig = px.bar(
                plan_df, x="count", y="plan", orientation="h",
                title="Top 10 Proposed Plans"
            )
            fig.update_layout(margin=dict(l=10, r=10, t=60, b=10), height=360, template="plotly_dark")
            st.plotly_chart(fig, use_container_width=True)

    # Customer mix table (bank vs non-bank)
    if "customer_type" in cols:
        mix = df["customer_type"].value_counts().rename_axis("Customer Type").reset_index(name="Count")
        mix["Ratio"] = (mix["Count"] / mix["Count"].sum()).round(3)
        st.markdown("### ğŸ‘¥ Customer Mix")
        st.dataframe(mix, use_container_width=True, height=220)



# DATA GENERATORS

def generate_raw_synthetic(n: int, non_bank_ratio: float) -> pd.DataFrame:
    rng = np.random.default_rng(42)
    names = ["Alice Nguyen","Bao Tran","Chris Do","Duy Le","Emma Tran",
             "Felix Nguyen","Giang Ho","Hanh Vo","Ivan Pham","Julia Ngo"]
    emails = [f"{n.split()[0].lower()}.{n.split()[1].lower()}@gmail.com" for n in names]
    addrs = [
        "23 Elm St, Boston, MA","19 Pine Ave, San Jose, CA","14 High St, London, UK",
        "55 Nguyen Hue, Ho Chi Minh","78 Oak St, Chicago, IL","10 Broadway, New York, NY",
        "8 Rue Lafayette, Paris, FR","21 KÃ¶nigstr, Berlin, DE","44 Maple Dr, Los Angeles, CA","22 Bay St, Toronto, CA"
    ]
    is_non = rng.random(n) < non_bank_ratio
    cust_type = np.where(is_non, "non-bank", "bank")

    df = pd.DataFrame({
        "application_id": [f"APP_{i:04d}" for i in range(1, n + 1)],
        "customer_name": np.random.choice(names, n),
        "email": np.random.choice(emails, n),
        "phone": [f"+1-202-555-{1000+i:04d}" for i in range(n)],
        "address": np.random.choice(addrs, n),
        "national_id": rng.integers(10_000_000, 99_999_999, n),
        "age": rng.integers(21, 65, n),
        "income": rng.integers(25_000, 150_000, n),
        "employment_length": rng.integers(0, 30, n),
        "loan_amount": rng.integers(5_000, 100_000, n),
        "loan_duration_months": rng.choice([12, 24, 36, 48, 60, 72], n),
        "collateral_value": rng.integers(8_000, 200_000, n),
        "collateral_type": rng.choice(["real_estate","car","land","deposit"], n),
        "co_loaners": rng.choice([0,1,2], n, p=[0.7, 0.25, 0.05]),
        "credit_score": rng.integers(300, 850, n),
        "existing_debt": rng.integers(0, 50_000, n),
        "assets_owned": rng.integers(10_000, 300_000, n),
        "current_loans": rng.integers(0, 5, n),
        "customer_type": cust_type,
    })
    eps = 1e-9
    df["DTI"] = df["existing_debt"] / (df["income"] + eps)
    df["LTV"] = df["loan_amount"] / (df["collateral_value"] + eps)
    df["CCR"] = df["collateral_value"] / (df["loan_amount"] + eps)
    df["ITI"] = (df["loan_amount"] / (df["loan_duration_months"] + eps)) / (df["income"] + eps)
    df["CWI"] = ((1 - df["DTI"]).clip(0, 1)) * ((1 - df["LTV"]).clip(0, 1)) * (df["CCR"].clip(0, 3))

    fx = st.session_state["currency_fx"]
    for c in ("income", "loan_amount", "collateral_value", "assets_owned", "existing_debt"):
        df[c] = (df[c] * fx).round(2)
    df["currency_code"] = st.session_state["currency_code"]
    return dedupe_columns(df)

def generate_anon_synthetic(n: int, non_bank_ratio: float) -> pd.DataFrame:
    rng = np.random.default_rng(42)
    is_non = rng.random(n) < non_bank_ratio
    cust_type = np.where(is_non, "non-bank", "bank")

    df = pd.DataFrame({
        "application_id": [f"APP_{i:04d}" for i in range(1, n + 1)],
        "age": rng.integers(21, 65, n),
        "income": rng.integers(25_000, 150_000, n),
        "employment_length": rng.integers(0, 30, n),
        "loan_amount": rng.integers(5_000, 100_000, n),
        "loan_duration_months": rng.choice([12, 24, 36, 48, 60, 72], n),
        "collateral_value": rng.integers(8_000, 200_000, n),
        "collateral_type": rng.choice(["real_estate","car","land","deposit"], n),
        "co_loaners": rng.choice([0,1,2], n, p=[0.7, 0.25, 0.05]),
        "credit_score": rng.integers(300, 850, n),
        "existing_debt": rng.integers(0, 50_000, n),
        "assets_owned": rng.integers(10_000, 300_000, n),
        "current_loans": rng.integers(0, 5, n),
        "customer_type": cust_type,
    })
    eps = 1e-9
    df["DTI"] = df["existing_debt"] / (df["income"] + eps)
    df["LTV"] = df["loan_amount"] / (df["collateral_value"] + eps)
    df["CCR"] = df["collateral_value"] / (df["loan_amount"] + eps)
    df["ITI"] = (df["loan_amount"] / (df["loan_duration_months"] + eps)) / (df["income"] + eps)
    df["CWI"] = ((1 - df["DTI"]).clip(0, 1)) * ((1 - df["LTV"]).clip(0, 1)) * (df["CCR"].clip(0, 3))

    fx = st.session_state["currency_fx"]
    for c in ("income", "loan_amount", "collateral_value", "assets_owned", "existing_debt"):
        df[c] = (df[c] * fx).round(2)
    df["currency_code"] = st.session_state["currency_code"]
    return dedupe_columns(df)

def to_agent_schema(df: pd.DataFrame) -> pd.DataFrame:
    """
    Harmonize to the server-side agentâ€™s expected schema.
    """
    out = df.copy()
    n = len(out)
    if "employment_years" not in out.columns:
        out["employment_years"] = out.get("employment_length", 0)
    if "debt_to_income" not in out.columns:
        if "DTI" in out.columns:
            out["debt_to_income"] = out["DTI"].astype(float)
        elif "existing_debt" in out.columns and "income" in out.columns:
            denom = out["income"].replace(0, np.nan)
            dti = (out["existing_debt"] / denom).fillna(0.0)
            out["debt_to_income"] = dti.clip(0, 10)
        else:
            out["debt_to_income"] = 0.0
    rng = np.random.default_rng(12345)
    if "credit_history_length" not in out.columns:
        out["credit_history_length"] = rng.integers(0, 30, n)
    if "num_delinquencies" not in out.columns:
        out["num_delinquencies"] = np.minimum(rng.poisson(0.2, n), 10)
    if "requested_amount" not in out.columns:
        out["requested_amount"] = out.get("loan_amount", 0)
    if "loan_term_months" not in out.columns:
        out["loan_term_months"] = out.get("loan_duration_months", 0)
    return dedupe_columns(out)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOGIN
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ss["credit_stage"] == "login" and not ss["credit_logged_in"]:
  render_nav_bar_app()
  st.title("ğŸ” Login to Credit Appraisal Platform")
  c1,c2,c3 = st.columns([1,1,1])
  with c1: user = st.text_input("Username")
  with c2: email = st.text_input("Email")
  with c3: pwd = st.text_input("Password", type="password")
  if st.button("Login"):
    if user and email:
      ss["credit_user"] = {"name":user,"email":email,
        "timestamp":datetime.now(timezone.utc).isoformat()}
      ss["credit_logged_in"]=True
      ss["credit_stage"]="credit_flow"
      st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN WORKFLOW â€” appears after successful login
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif ss.get("credit_logged_in", False):
    render_nav_bar_app()
    st.title("ğŸ’³ Credit Appraisal Agent")
    st.caption(f"E2E flow â€” Synthetic â†’ Anonymize â†’ AI â†’ Review â†’ Retrain | ğŸ‘‹ {ss['credit_user']['name']}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # WORKFLOW TABS â€” full 6 steps
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tab_gen, tab_clean, tab_run, tab_review, tab_train, tab_feedback = st.tabs([
        "ğŸ¦ Synthetic Data Generator",
        "ğŸ§¹ Anonymize & Sanitize Data",
        "ğŸ¤– Credit appraisal by AI assistant",
        "ğŸ§‘â€âš–ï¸ Human Review",
        "ğŸ” Training (Feedback â†’ Retrain)",
        "ğŸ—£ï¸ Feedback & Feature Requests"
    ])



    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ¦ TAB 1 â€” Synthetic Data Generator
    with tab_gen:
        st.subheader("ğŸ¦ Synthetic Credit Data Generator")

        # Currency selector (before generation)
        c1, c2 = st.columns([1, 2])
        with c1:
            code = st.selectbox(
                "Currency",
                list(CURRENCY_OPTIONS.keys()),
                index=list(CURRENCY_OPTIONS.keys()).index(st.session_state["currency_code"]),
                help="All monetary fields will be in this local currency."
            )
            if code != st.session_state["currency_code"]:
                st.session_state["currency_code"] = code
                set_currency_defaults()
        #with c2:
            #st.info(f"Amounts will be generated in **{st.session_state['currency_label']}**.", icon="ğŸ’°")
        with c2:
            st.markdown(
                f"""
                <div style='background-color:#1e293b; padding:12px 16px; border-radius:8px;'>
                    <span style='font-weight:600; color:#f8fafc;'>
                        ğŸ’° Amounts will be generated in
                        <span style='color:#4ade80;'>{st.session_state['currency_label']}</span>.
                    </span>
                </div>
                """,
                unsafe_allow_html=True,
            )


        rows = st.slider("Number of rows to generate", 50, 2000, 200, step=50)
        non_bank_ratio = st.slider("Share of non-bank customers", 0.0, 1.0, 0.30, 0.05)

        colA, colB = st.columns(2)
        with colA:
            if st.button("ğŸ”´ Generate RAW Synthetic Data (with PII)", use_container_width=True):
                raw_df = append_user_info(generate_raw_synthetic(rows, non_bank_ratio))
                st.session_state.synthetic_raw_df = raw_df
                raw_path = save_to_runs(raw_df, "synthetic_raw")
                st.success(f"Generated RAW (PII) dataset with {rows} rows in {st.session_state['currency_label']}. Saved to {raw_path}")
                st.dataframe(raw_df.head(10), use_container_width=True)
                st.download_button(
                    "â¬‡ï¸ Download RAW CSV",
                    raw_df.to_csv(index=False).encode("utf-8"),
                    os.path.basename(raw_path),
                    "text/csv"
                )

        with colB:
            if st.button("ğŸŸ¢ Generate ANON Synthetic Data (ready for agent)", use_container_width=True):
                anon_df = append_user_info(generate_anon_synthetic(rows, non_bank_ratio))
                st.session_state.synthetic_df = anon_df
                anon_path = save_to_runs(anon_df, "synthetic_anon")
                st.success(f"Generated ANON dataset with {rows} rows in {st.session_state['currency_label']}. Saved to {anon_path}")
                st.dataframe(anon_df.head(10), use_container_width=True)
                st.download_button(
                    "â¬‡ï¸ Download ANON CSV",
                    anon_df.to_csv(index=False).encode("utf-8"),
                    os.path.basename(anon_path),
                    "text/csv"
                )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ§¹ TAB 2 â€” Anonymize & Sanitize Data
    with tab_clean:
        st.subheader("ğŸ§¹ Upload & Anonymize Customer Data (PII columns will be DROPPED)")
        st.markdown("Upload your **real CSV**. We drop PII columns and scrub emails/phones in text fields.")

        uploaded = st.file_uploader("Upload CSV file", type=["csv"])
        if uploaded:
            try:
                df = pd.read_csv(uploaded)
            except Exception as e:
                st.error(f"Could not read CSV: {e}")
                st.stop()

            st.write("ğŸ“Š Original Data Preview:")
            st.dataframe(dedupe_columns(df.head(5)), use_container_width=True)

            sanitized, dropped_cols = drop_pii_columns(df)
            sanitized = append_user_info(sanitized)
            sanitized = dedupe_columns(sanitized)
            st.session_state.anonymized_df = sanitized

            st.success(f"Dropped PII columns: {sorted(dropped_cols) if dropped_cols else 'None'}")
            st.write("âœ… Sanitized Data Preview:")
            st.dataframe(sanitized.head(5), use_container_width=True)

            fpath = save_to_runs(sanitized, "anonymized")
            st.success(f"Saved anonymized file: {fpath}")
            st.download_button(
                "â¬‡ï¸ Download Clean Data",
                sanitized.to_csv(index=False).encode("utf-8"),
                os.path.basename(fpath),
                "text/csv"
            )
        else:
            st.info("Choose a CSV to see the sanitize flow.", icon="â„¹ï¸")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ¤– TAB 3 â€” Credit appraisal by AI assistant
    with tab_run:
        st.subheader("ğŸ¤– Credit appraisal by AI assistant")
        # Anchor for loopback link from Training tab
        st.markdown('<a name="credit-appraisal-stage"></a>', unsafe_allow_html=True)

        # Production model banner (optional)
        try:
            resp = requests.get(f"{API_URL}/v1/training/production_meta", timeout=5)
            if resp.status_code == 200:
                meta = resp.json()
                if meta.get("has_production"):
                    ver = (meta.get("meta") or {}).get("version", "1.x")
                    src = (meta.get("meta") or {}).get("source", "production")
                    st.success(f"ğŸŸ¢ Production model active â€” version: {ver} â€¢ source: {src}")
                else:
                    st.warning("âš ï¸ No production model promoted yet â€” using baseline.")
            else:
                st.info("â„¹ï¸ Could not fetch production model meta.")
        except Exception:
            st.info("â„¹ï¸ Production meta unavailable.")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ§© Model Selection (list all trained models)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        trained_dir = os.path.expanduser(
            "~/credit-appraisal-agent-poc/agents/credit_appraisal/models/trained"
        )
        models = []
        if os.path.exists(trained_dir):
            for f in os.listdir(trained_dir):
                if f.endswith(".joblib"):
                    fpath = os.path.join(trained_dir, f)
                    ctime = os.path.getctime(fpath)
                    #created = datetime.datetime.fromtimestamp(ctime).strftime("%b %d, %Y %H:%M")
                    created = datetime.fromtimestamp(ctime, tz=timezone.utc).strftime("%b %d, %Y %H:%M")
                    models.append((f, fpath, created))

        if models:
            models.sort(key=lambda x: x[2], reverse=True)
            display_names = [f"{m[0]} â€” {m[2]}" for m in models]

            selected_display = st.selectbox("ğŸ“¦ Select trained model to use", display_names)
            selected_model = models[display_names.index(selected_display)][1]
            st.success(f"âœ… Using model: {os.path.basename(selected_model)}")

            # Store for later use by /run API
            st.session_state["selected_trained_model"] = selected_model

            # Optional promote button
            if st.button("ğŸš€ Promote this model to Production"):
                try:
                    prod_path = os.path.expanduser(
                        "~/credit-appraisal-agent-poc/agents/credit_appraisal/models/production/model.joblib"
                    )
                    os.makedirs(os.path.dirname(prod_path), exist_ok=True)
                    import shutil
                    shutil.copy2(selected_model, prod_path)
                    st.success(f"âœ… Model promoted to production: {os.path.basename(prod_path)}")
                except Exception as e:
                    st.error(f"âŒ Promotion failed: {e}")
        else:
            st.warning("âš ï¸ No trained models found â€” train one in Step 5 first.")

        # 1) Model + Hardware selection (UI hints)
        LLM_MODELS = [
            ("Phi-3 Mini (3.8B) â€” CPU OK", "phi3:3.8b", "CPU 8GB RAM (fast)"),
            ("Mistral 7B Instruct â€” CPU slow / GPU OK", "mistral:7b-instruct", "CPU 16GB (slow) or GPU â‰¥8GB"),
            ("Gemma-2 7B â€” CPU slow / GPU OK", "gemma2:7b", "CPU 16GB (slow) or GPU â‰¥8GB"),
            ("LLaMA-3 8B â€” GPU recommended", "llama3:8b-instruct", "GPU â‰¥12GB (CPU very slow)"),
            ("Qwen2 7B â€” GPU recommended", "qwen2:7b-instruct", "GPU â‰¥12GB (CPU very slow)"),
            ("Mixtral 8x7B â€” GPU only (big)", "mixtral:8x7b-instruct", "GPU 24â€“48GB"),
        ]
        LLM_LABELS = [l for (l, _, _) in LLM_MODELS]
        LLM_VALUE_BY_LABEL = {l: v for (l, v, _) in LLM_MODELS}
        LLM_HINT_BY_LABEL = {l: h for (l, _, h) in LLM_MODELS}

        OPENSTACK_FLAVORS = {
            "m4.medium":  "4 vCPU / 8 GB RAM â€” CPU-only small",
            "m8.large":   "8 vCPU / 16 GB RAM â€” CPU-only medium",
            "g1.a10.1":   "8 vCPU / 32 GB RAM + 1Ã—A10 24GB",
            "g1.l40.1":   "16 vCPU / 64 GB RAM + 1Ã—L40 48GB",
            "g2.a100.1":  "24 vCPU / 128 GB RAM + 1Ã—A100 80GB",
        }

        with st.expander("ğŸ§  Local LLM & Hardware Profile", expanded=True):
            c1, c2 = st.columns([1.2, 1])
            with c1:
                model_label = st.selectbox("Local LLM (used for narratives/explanations)", LLM_LABELS, index=1)
                llm_value = LLM_VALUE_BY_LABEL[model_label]
                st.caption(f"Hint: {LLM_HINT_BY_LABEL[model_label]}")
            with c2:
                flavor = st.selectbox("OpenStack flavor / host profile", list(OPENSTACK_FLAVORS.keys()), index=0)
                st.caption(OPENSTACK_FLAVORS[flavor])
            st.caption("These are passed to the API as hints; your API can choose Ollama/Flowise backends accordingly.")

        # 2) Data Source
        data_choice = st.selectbox(
            "Select Data Source",
            [
                "Use synthetic (ANON)",
                "Use synthetic (RAW â€“ auto-sanitize)",
                "Use anonymized dataset",
                "Upload manually",
            ]
        )
        use_llm = st.checkbox("Use LLM narrative", value=False)
        agent_name = "credit_appraisal"

        if data_choice == "Upload manually":
            up = st.file_uploader("Upload your CSV", type=["csv"], key="manual_upload_run_file")
            if up is not None:
                st.session_state["manual_upload_name"] = up.name
                st.session_state["manual_upload_bytes"] = up.getvalue()
                st.success(f"File staged: {up.name} ({len(st.session_state['manual_upload_bytes'])} bytes)")

        # 3) Rules
        st.markdown("### âš™ï¸ Decision Rule Set")
        rule_mode = st.radio(
            "Choose rule mode",
            ["Classic (bank-style metrics)", "NDI (Net Disposable Income) â€” simple"],
            index=0,
            help="NDI = income - all monthly obligations. Approve if NDI and NDI ratio pass thresholds."
        )

        CLASSIC_DEFAULTS = {
            "max_dti": 0.45, "min_emp_years": 2, "min_credit_hist": 3, "salary_floor": 3000,
            "max_delinquencies": 2, "max_current_loans": 3, "req_min": 1000, "req_max": 200000,
            "loan_terms": [12, 24, 36, 48, 60], "threshold": 0.45, "target_rate": None, "random_band": True,
            "min_income_debt_ratio": 0.35, "compounded_debt_factor": 1.0, "monthly_debt_relief": 0.50,
        }
        NDI_DEFAULTS = {"ndi_value": 800.0, "ndi_ratio": 0.50, "threshold": 0.45, "target_rate": None, "random_band": True}

        if "classic_rules" not in st.session_state:
            st.session_state.classic_rules = CLASSIC_DEFAULTS.copy()
        if "ndi_rules" not in st.session_state:
            st.session_state.ndi_rules = NDI_DEFAULTS.copy()

        def reset_classic(): st.session_state.classic_rules = CLASSIC_DEFAULTS.copy()
        def reset_ndi():     st.session_state.ndi_rules = NDI_DEFAULTS.copy()

        if rule_mode.startswith("Classic"):
            with st.expander("Classic Metrics (with Reset)", expanded=True):
                rc = st.session_state.classic_rules
                r1, r2, r3 = st.columns(3)
                with r1:
                    rc["max_dti"] = st.slider("Max Debt-to-Income (DTI)", 0.0, 1.0, rc["max_dti"], 0.01)
                    rc["min_emp_years"] = st.number_input("Min Employment Years", 0, 40, rc["min_emp_years"])
                    rc["min_credit_hist"] = st.number_input("Min Credit History (years)", 0, 40, rc["min_credit_hist"])
                with r2:
                    rc["salary_floor"] = st.number_input("Minimum Monthly Salary", 0, 1_000_000_000, rc["salary_floor"], step=1000, help=fmt_currency_label("in local currency"))
                    rc["max_delinquencies"] = st.number_input("Max Delinquencies", 0, 10, rc["max_delinquencies"])
                    rc["max_current_loans"] = st.number_input("Max Current Loans", 0, 10, rc["max_current_loans"])
                with r3:
                    rc["req_min"] = st.number_input(fmt_currency_label("Requested Amount Min"), 0, 10_000_000_000, rc["req_min"], step=1000)
                    rc["req_max"] = st.number_input(fmt_currency_label("Requested Amount Max"), 0, 10_000_000_000, rc["req_max"], step=1000)
                    rc["loan_terms"] = st.multiselect("Allowed Loan Terms (months)", [12,24,36,48,60,72], default=rc["loan_terms"])

                st.markdown("#### ğŸ§® Debt Pressure Controls")
                d1, d2, d3 = st.columns(3)
                with d1:
                    rc["min_income_debt_ratio"] = st.slider("Min Income / (Compounded Debt) Ratio", 0.10, 2.00, rc["min_income_debt_ratio"], 0.01)
                with d2:
                    rc["compounded_debt_factor"] = st.slider("Compounded Debt Factor (Ã— requested)", 0.5, 3.0, rc["compounded_debt_factor"], 0.1)
                with d3:
                    rc["monthly_debt_relief"] = st.slider("Monthly Debt Relief Factor", 0.10, 1.00, rc["monthly_debt_relief"], 0.05)

                st.markdown("---")
                c1, c2, c3 = st.columns([1,1,1])
                with c1:
                    use_target = st.toggle("ğŸ¯ Use target approval rate", value=(rc["target_rate"] is not None))
                with c2:
                    rc["random_band"] = st.toggle("ğŸ² Randomize approval band (20â€“60%) when no target", value=rc["random_band"])
                with c3:
                    if st.button("â†©ï¸ Reset to defaults"):
                        reset_classic()
                        st.rerun()

                if use_target:
                    rc["target_rate"] = st.slider("Target approval rate", 0.05, 0.95, rc["target_rate"] or 0.40, 0.01)
                    rc["threshold"] = None
                else:
                    rc["threshold"] = st.slider("Model score threshold", 0.0, 1.0, rc["threshold"], 0.01)
                    rc["target_rate"] = None
        else:
            with st.expander("NDI Metrics (with Reset)", expanded=True):
                rn = st.session_state.ndi_rules
                n1, n2 = st.columns(2)
                with n1:
                    rn["ndi_value"] = st.number_input(fmt_currency_label("Min NDI (Net Disposable Income) per month"), 0.0, 1e12, float(rn["ndi_value"]), step=50.0)
                with n2:
                    rn["ndi_ratio"] = st.slider("Min NDI / Income ratio", 0.0, 1.0, float(rn["ndi_ratio"]), 0.01)
                st.caption("NDI = income - all monthly obligations (rent, food, loans, cards, etc.).")

                st.markdown("---")
                c1, c2, c3 = st.columns([1,1,1])
                with c1:
                    use_target = st.toggle("ğŸ¯ Use target approval rate", value=(rn["target_rate"] is not None))
                with c2:
                    rn["random_band"] = st.toggle("ğŸ² Randomize approval band (20â€“60%) when no target", value=rn["random_band"])
                with c3:
                    if st.button("â†©ï¸ Reset to defaults (NDI)"):
                        reset_ndi()
                        st.rerun()

                if use_target:
                    rn["target_rate"] = st.slider("Target approval rate", 0.05, 0.95, rn["target_rate"] or 0.40, 0.01)
                    rn["threshold"] = None
                else:
                    rn["threshold"] = st.slider("Model score threshold", 0.0, 1.0, rn["threshold"], 0.01)
                    rn["target_rate"] = None

        # 4) Run
        if st.button("ğŸš€ Run Agent", use_container_width=True):
            try:
                files = None
                data: Dict[str, Any] = {
                    "use_llm_narrative": str(use_llm).lower(),
                    "llm_model": llm_value,
                    "hardware_flavor": flavor,
                    "currency_code": st.session_state["currency_code"],
                    "currency_symbol": st.session_state["currency_symbol"],
                }
                if rule_mode.startswith("Classic"):
                    rc = st.session_state.classic_rules
                    data.update({
                        "min_employment_years": str(rc["min_emp_years"]),
                        "max_debt_to_income": str(rc["max_dti"]),
                        "min_credit_history_length": str(rc["min_credit_hist"]),
                        "max_num_delinquencies": str(rc["max_delinquencies"]),
                        "max_current_loans": str(rc["max_current_loans"]),
                        "requested_amount_min": str(rc["req_min"]),
                        "requested_amount_max": str(rc["req_max"]),
                        "loan_term_months_allowed": ",".join(map(str, rc["loan_terms"])) if rc["loan_terms"] else "",
                        "min_income_debt_ratio": str(rc["min_income_debt_ratio"]),
                        "compounded_debt_factor": str(rc["compounded_debt_factor"]),
                        "monthly_debt_relief": str(rc["monthly_debt_relief"]),
                        "salary_floor": str(rc["salary_floor"]),
                        "threshold": "" if rc["threshold"] is None else str(rc["threshold"]),
                        "target_approval_rate": "" if rc["target_rate"] is None else str(rc["target_rate"]),
                        "random_band": str(rc["random_band"]).lower(),
                        "random_approval_band": str(rc["random_band"]).lower(),
                        "rule_mode": "classic",
                    })
                else:
                    rn = st.session_state.ndi_rules
                    data.update({
                        "ndi_value": str(rn["ndi_value"]),
                        "ndi_ratio": str(rn["ndi_ratio"]),
                        "threshold": "" if rn["threshold"] is None else str(rn["threshold"]),
                        "target_approval_rate": "" if rn["target_rate"] is None else str(rn["target_rate"]),
                        "random_band": str(rn["random_band"]).lower(),
                        "random_approval_band": str(rn["random_band"]).lower(),
                        "rule_mode": "ndi",
                    })

                def prep_and_pack(df: pd.DataFrame, filename: str):
                    safe = dedupe_columns(df)
                    safe, _ = drop_pii_columns(safe)
                    safe = strip_policy_banned(safe)
                    safe = to_agent_schema(safe)
                    buf = io.StringIO()
                    safe.to_csv(buf, index=False)
                    return {"file": (filename, buf.getvalue().encode("utf-8"), "text/csv")}

                if data_choice == "Use synthetic (ANON)":
                    if "synthetic_df" not in st.session_state:
                        st.warning("No ANON synthetic dataset found. Generate it in the first tab."); st.stop()
                    files = prep_and_pack(st.session_state.synthetic_df, "synthetic_anon.csv")

                elif data_choice == "Use synthetic (RAW â€“ auto-sanitize)":
                    if "synthetic_raw_df" not in st.session_state:
                        st.warning("No RAW synthetic dataset found. Generate it in the first tab."); st.stop()
                    files = prep_and_pack(st.session_state.synthetic_raw_df, "synthetic_raw_sanitized.csv")

                elif data_choice == "Use anonymized dataset":
                    if "anonymized_df" not in st.session_state:
                        st.warning("No anonymized dataset found. Create it in the second tab."); st.stop()
                    files = prep_and_pack(st.session_state.anonymized_df, "anonymized.csv")

                elif data_choice == "Upload manually":
                    up_name = st.session_state.get("manual_upload_name")
                    up_bytes = st.session_state.get("manual_upload_bytes")
                    if not up_name or not up_bytes:
                        st.warning("Please upload a CSV first."); st.stop()
                    try:
                        tmp_df = pd.read_csv(io.BytesIO(up_bytes))
                        files = prep_and_pack(tmp_df, up_name)
                    except Exception:
                        files = {"file": (up_name, up_bytes, "text/csv")}
                else:
                    st.error("Unknown data source selection."); st.stop()

                # ---- RUN REQUEST ----
                r = requests.post(
                    f"{API_URL}/v1/agents/{agent_name}/run",
                    data=data,
                    files=files,
                    timeout=180
                )

                if r.status_code != 200:
                    st.error(f"Run failed ({r.status_code}): {r.text}")
                    st.stop()

                res = r.json()

                # ---- Robust run_id + data extraction ----
                run_id = None
                payload_rows = None  # fallback rows for rendering

                if isinstance(res, dict):
                    run_id = res.get("run_id") or res.get("id")
                    payload_rows = res.get("result") or res.get("data") or res.get("results") or res.get("rows")
                elif isinstance(res, list):
                    payload_rows = res
                else:
                    try:
                        maybe = json.loads(res)
                        if isinstance(maybe, dict):
                            run_id = maybe.get("run_id") or maybe.get("id")
                            payload_rows = maybe.get("result") or maybe.get("data") or maybe.get("results") or maybe.get("rows")
                        elif isinstance(maybe, list):
                            payload_rows = maybe
                    except Exception:
                        pass

                # ---- Helper: turn any JSON-like into a DataFrame ----
                def json_to_df(obj) -> pd.DataFrame:
                    if obj is None:
                        return pd.DataFrame()
                    if isinstance(obj, pd.DataFrame):
                        return obj
                    if isinstance(obj, bytes):
                        try:
                            obj = obj.decode("utf-8", errors="ignore")
                        except Exception:
                            return pd.DataFrame({"value": [repr(obj)]})
                    if isinstance(obj, str):
                        obj = obj.strip()
                        if not obj:
                            return pd.DataFrame()
                        try:
                            j = json.loads(obj)
                            return json_to_df(j)
                        except Exception:
                            lines = [ln for ln in obj.splitlines() if ln.strip()]
                            return pd.DataFrame({"value": lines}) if lines else pd.DataFrame()
                    if isinstance(obj, list):
                        if len(obj) == 0:
                            return pd.DataFrame()
                        if all(isinstance(x, dict) for x in obj):
                            try:
                                return pd.json_normalize(obj)
                            except Exception:
                                return pd.DataFrame(obj)
                        if all(isinstance(x, list) for x in obj):
                            return pd.DataFrame({"row": obj})
                        return pd.DataFrame({"value": obj})
                    if isinstance(obj, dict):
                        for key in ("rows", "data", "result", "results", "items", "records"):
                            if key in obj and isinstance(obj[key], (list, dict)):
                                return json_to_df(obj[key])
                        try:
                            return pd.json_normalize(obj)
                        except Exception:
                            return pd.DataFrame([obj])
                    return pd.DataFrame({"value": [obj]})

                # ---- Prefer server report via run_id; otherwise fall back to local JSONâ†’DF ----
                merged_df = pd.DataFrame()
                if run_id:
                    try:
                        rid = run_id
                        merged_url = f"{API_URL}/v1/runs/{rid}/report?format=csv"
                        merged_bytes = requests.get(merged_url, timeout=30).content
                        merged_df = pd.read_csv(io.BytesIO(merged_bytes))
                        st.session_state.last_run_id = rid
                        st.success(f"âœ… Run succeeded! Run ID: {rid}")
                    except Exception as e:
                        st.warning(f"Could not fetch merged CSV via run_id ({run_id}): {e}")
                        merged_df = json_to_df(payload_rows)
                else:
                    st.warning("âš ï¸ Backend did not return a run_id. Rendering raw response as table.")
                    merged_df = json_to_df(payload_rows if payload_rows is not None else res)

                if merged_df is None or merged_df.empty:
                    st.error("No data available to render (both report and fallback JSON were empty).")
                    st.write("Raw response:", res)
                    st.stop()

                # Keep for later tabs
                st.session_state["last_merged_df"] = dedupe_columns(merged_df)

                # ---- Decisions Table (with filter) ----
                st.markdown("### ğŸ“„ Credit AI Agent Decisions Table (filtered)")
                uniq_dec = sorted([d for d in merged_df.get("decision", pd.Series(dtype=str)).dropna().unique()]) \
                        if "decision" in merged_df.columns else []
                chosen = st.multiselect("Filter decision", options=uniq_dec, default=uniq_dec, key="filter_decisions")
                df_view = merged_df.copy()
                if "decision" in df_view.columns and chosen:
                    df_view = df_view[df_view["decision"].isin(chosen)]
                st.dataframe(df_view, use_container_width=True)

                # ---- Dashboard ----
                st.markdown("## ğŸ“Š Dashboard")
                render_credit_dashboard(merged_df, st.session_state.get("currency_symbol", ""))

                # Add per-row metrics columns if present
                if "rule_reasons" in df_view.columns:
                    rr = df_view["rule_reasons"].apply(try_json)
                    df_view["metrics_met"] = rr.apply(lambda d: ", ".join(sorted([k for k, v in (d or {}).items() if v is True])) if isinstance(d, dict) else "")
                    df_view["metrics_unmet"] = rr.apply(lambda d: ", ".join(sorted([k for k, v in (d or {}).items() if v is False])) if isinstance(d, dict) else "")

                cols_show = [c for c in [
                    "application_id","customer_type","decision","score","loan_amount","income","metrics_met","metrics_unmet",
                    "proposed_loan_option","proposed_consolidation_loan","top_feature","explanation"
                ] if c in df_view.columns]
                if cols_show:
                    st.dataframe(df_view[cols_show].head(500), use_container_width=True)

                # ---- Download button (keep your large button style) ----
                ts = datetime.now(timezone.utc).strftime("%Y%m%d-%H%M%S")
                out_name = f"ai-appraisal-outputs-{ts}-{st.session_state['currency_code']}.csv"
                csv_data = merged_df.to_csv(index=False).encode("utf-8")

                st.markdown("""
                <style>
                div[data-testid="stDownloadButton"] button {
                    font-size: 90px !important;
                    font-weight: 900 !important;
                    padding: 28px 48px !important;
                    border-radius: 16px !important;
                    background: linear-gradient(90deg, #2563eb, #1d4ed8) !important;
                    color: white !important;
                    border: none !important;
                    box-shadow: 0 6px 18px rgba(0,0,0,0.35) !important;
                    transition: all 0.3s ease-in-out !important;
                }
                div[data-testid="stDownloadButton"] button:hover {
                    background: linear-gradient(90deg, #1e3a8a, #1d4ed8) !important;
                    transform: scale(1.03);
                }
                </style>
                """, unsafe_allow_html=True)

                st.download_button(
                    "â¬‡ï¸ Download AI Outputs For Human Review (CSV)",
                    csv_data,
                    file_name=out_name,
                    mime="text/csv",
                    use_container_width=True
                )
            except Exception as e:
                st.exception(e)



        # Re-download quick section
        if st.session_state.get("last_run_id"):
            st.markdown("---")
            st.subheader("ğŸ“¥ Download Latest Outputs")
            rid = st.session_state.last_run_id
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1: st.markdown(f"[â¬‡ï¸ PDF]({API_URL}/v1/runs/{rid}/report?format=pdf)")
            with col2: st.markdown(f"[â¬‡ï¸ Scores CSV]({API_URL}/v1/runs/{rid}/report?format=scores_csv)")
            with col3: st.markdown(f"[â¬‡ï¸ Explanations CSV]({API_URL}/v1/runs/{rid}/report?format=explanations_csv)")
            with col4: st.markdown(f"[â¬‡ï¸ Merged CSV]({API_URL}/v1/runs/{rid}/report?format=csv)")
            with col5: st.markdown(f"[â¬‡ï¸ JSON]({API_URL}/v1/runs/{rid}/report?format=json)")


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ§‘â€âš–ï¸ TAB 4 â€” Human Review
    with tab_review:
        st.subheader("ğŸ§‘â€âš–ï¸ Human Review â€” Correct AI Decisions & Score Agreement > Drop your AI appraisal output CSV from previous Stage  below")

        # Allow loading AI output CSV back into review via dropdown upload
        uploaded_review = st.file_uploader("Load AI outputs CSV for review (optional)", type=["csv"], key="review_csv_loader")
        if uploaded_review is not None:
            try:
                st.session_state["last_merged_df"] = pd.read_csv(uploaded_review)
                st.success("Loaded review dataset from uploaded CSV.")
            except Exception as e:
                st.error(f"Could not read uploaded CSV: {e}")

        if "last_merged_df" not in st.session_state:
            st.info("Run the agent (previous tab) or upload an AI outputs CSV to load results for review.")
        else:
            dfm = st.session_state["last_merged_df"].copy()
            st.markdown("#### 1) Select rows to review and correct")

            editable_cols = []
            if "decision" in dfm.columns: editable_cols.append("decision")
            if "rule_reasons" in dfm.columns: editable_cols.append("rule_reasons")
            if "customer_type" in dfm.columns: editable_cols.append("customer_type")

            editable = dfm[["application_id"] + editable_cols].copy()
            editable.rename(columns={"decision": "ai_decision"}, inplace=True)
            editable["human_decision"] = editable.get("ai_decision", "approved")
            editable["human_rule_reasons"] = editable.get("rule_reasons", "")

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # LIGHTER EDITABLE CELL STYLING (improved)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            st.markdown("""
                <style>
                /* Bright background for editable cells */
                [data-testid="stDataFrameCellEditable"] textarea {
                    background-color: #fefefe !important;   /* bright white background */
                    color: #111 !important;                 /* dark text */
                    border: 1px solid #cbd5e1 !important;   /* subtle gray border */
                    border-radius: 6px !important;
                    padding: 6px 8px !important;
                    font-weight: 500 !important;
                }

                /* Hover and focus effect */
                [data-testid="stDataFrameCellEditable"]:focus-within textarea,
                [data-testid="stDataFrameCellEditable"]:hover textarea {
                    background-color: #ffffff !important;
                    border-color: #22c55e !important;        /* green glow */
                    box-shadow: 0 0 0 2px rgba(34,197,94,0.4) !important;
                }

                /* Read-only cells: keep dark */
                [data-testid="stDataFrameCell"] {
                    background-color: #1e293b !important;
                    color: #e2e8f0 !important;
                }
                </style>
            """, unsafe_allow_html=True)


            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # EDITOR
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

            edited = st.data_editor(
                editable,
                num_rows="dynamic",
                use_container_width=True,
                key="review_editor",
                column_config={
                    "human_decision": st.column_config.SelectboxColumn(options=["approved", "denied"]),
                    "customer_type": st.column_config.SelectboxColumn(options=["bank", "non-bank"], disabled=True)
                }
            )

            st.markdown("#### 2) Compute agreement score")

            if st.button("Compute agreement score"):
                if "ai_decision" in edited.columns and "human_decision" in edited.columns:
                    agree = (edited["ai_decision"] == edited["human_decision"]).astype(int)
                    score = float(agree.mean()) if len(agree) else 0.0
                    st.session_state["last_agreement_score"] = score

                    # ğŸŒ¡ï¸ BEAUTIFUL Gauge
                    import plotly.graph_objects as go
                    fig = go.Figure(go.Indicator(
                        mode="gauge+number",
                        value=score * 100,
                        number={'suffix': "%", 'font': {'size': 72, 'color': "#f8fafc", 'family': "Arial Black"}},
                        title={'text': "AI â†” Human Agreement", 'font': {'size': 28, 'color': "#93c5fd", 'family': "Arial"}},
                        gauge={
                            'axis': {'range': [0, 100], 'tickwidth': 2, 'tickcolor': "#f8fafc"},
                            'bar': {'color': "#3b82f6", 'thickness': 0.3},
                            'bgcolor': "#1e293b",
                            'borderwidth': 2,
                            'bordercolor': "#334155",
                            'steps': [
                                {'range': [0, 50], 'color': "#ef4444"},
                                {'range': [50, 75], 'color': "#f59e0b"},
                                {'range': [75, 100], 'color': "#22c55e"},
                            ],
                        }
                    ))
                    fig.update_layout(
                        paper_bgcolor="#0f172a",
                        plot_bgcolor="#0f172a",
                        height=400,
                        margin=dict(t=60, b=20, l=60, r=60)
                    )
                    st.plotly_chart(fig, use_container_width=True)



                # ğŸ’¡ Detailed disagreement table (AI vs Human + AI metrics explanation)
                    mismatched = edited[edited["ai_decision"] != edited["human_decision"]].copy()
                    total = len(edited)
                    disagree = len(mismatched)

                    if disagree > 0:
                        st.markdown(f"### âŒ {disagree} loans disagreed out of {total} ({(disagree/total)*100:.1f}% disagreement rate)")

                        import json

                        def parse_ai_reason(r: str):
                            """Parse AI rule_reasons and summarize which metrics passed or failed."""
                            if not isinstance(r, str):
                                return "No metrics available"
                            try:
                                data = json.loads(r.replace("'", "\""))
                                passed = [k for k, v in data.items() if v is True]
                                failed = [k for k, v in data.items() if v is False]
                                result = []
                                if passed:
                                    result.append("âœ… Pass: " + ", ".join(passed))
                                if failed:
                                    result.append("âŒ Fail: " + ", ".join(failed))
                                return " | ".join(result) if result else "No metrics recorded"
                            except Exception:
                                return "Unreadable metrics"

                        # Extract AI reasoning and Human reason columns
                        mismatched["ai_metrics"] = mismatched["rule_reasons"].apply(parse_ai_reason) if "rule_reasons" in mismatched else "No data"
                        mismatched["human_reason"] = mismatched.get("human_rule_reasons", "Manual review adjustment")

                        # ğŸŸ©ğŸŸ¥ Color styling for AI vs Human
                        def highlight_disagreement(row):
                            ai_color = "background-color: #ef4444; color: white;"      # red for AI decision
                            human_color = "background-color: #22c55e; color: black;"   # green for Human decision
                            return [
                                ai_color if col == "ai_decision" else
                                human_color if col == "human_decision" else
                                ""
                                for col in row.index
                            ]

                        # Columns: ID â†’ AI Decision â†’ Human Decision â†’ AI Metrics â†’ Human Reason
                        show_cols = [
                            c for c in ["application_id", "ai_decision", "human_decision", "ai_metrics", "human_reason"]
                            if c in mismatched.columns
                        ]
                        styled_df = mismatched[show_cols].style.apply(highlight_disagreement, axis=1)
                        st.dataframe(styled_df, use_container_width=True, height=420)

                    else:
                        st.success("âœ… Full agreement â€” no human-AI mismatches found.")



            # Export review CSV (manual loop into training)
            st.markdown("#### 3) Export Human review CSV for Next Step : Training and loopback ")
            model_used = "production"  # if you track specific model names, set it here
            ts = datetime.now(timezone.utc).strftime("%Y%m%d-%H%M%S")
            safe_user = st.session_state["user_info"]["name"].replace(" ", "").lower()
            review_name = f"creditappraisal.{safe_user}.{model_used}.{ts}.csv"
            csv_bytes = edited.to_csv(index=False).encode("utf-8")
            st.download_button("â¬‡ï¸ Export review CSV", csv_bytes, review_name, "text/csv")
            st.caption(f"Saved file name pattern: **{review_name}**")


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ” TAB 5 â€” Training (Feedback â†’ Retrain)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab_train:
        st.subheader("ğŸ” From Human Feedback CSV â†’ Train and Promote Trained Model to Production Model ")

        st.markdown("**Drag & drop** one or more review CSVs exported from the Human Review tab.")
        up_list = st.file_uploader("Upload feedback CSV(s)", type=["csv"], accept_multiple_files=True, key="train_feedback_uploader")

        staged_paths: List[str] = []
        if up_list:
            for up in up_list:
                # stage to tmp_feedback dir
                dest = os.path.join(TMP_FEEDBACK_DIR, up.name)
                with open(dest, "wb") as f:
                    f.write(up.getvalue())
                staged_paths.append(dest)
            st.success(f"Staged {len(staged_paths)} feedback file(s) to {TMP_FEEDBACK_DIR}")
            st.write(staged_paths)

        st.markdown("#### Launch Retrain")
        payload = {
            "feedback_csvs": staged_paths,
            "user_name": st.session_state["user_info"]["name"],
            "agent_name": "credit_appraisal",
            "algo_name": "credit_lr",
        }
        st.code(json.dumps(payload, indent=2), language="json")

        colA, colB = st.columns([1, 1])
        with colA:
            if st.button("ğŸš€ Train candidate model"):
                try:
                    r = requests.post(f"{API_URL}/v1/training/train", json=payload, timeout=90)
                    resp = r.json() if r.ok else None

                    # ğŸ§© INSERTED BLOCK â€” RETRAIN RESPONSE HANDLER
                    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    if resp and "model_path" in resp:
                        meta_path = resp["meta_path"]
                        meta = {
                            "job_id": resp["job_id"],
                            "model_name": resp["model_name"],
                            "model_path": resp["model_path"],
                            "meta_path": meta_path,
                            "metrics": resp.get("metrics", {}),
                            "feature_names": resp.get("feature_names", []),
                            "timestamp": datetime.now(timezone.utc).isoformat(),
                        }
                        with open(meta_path, "w") as f:
                            json.dump(meta, f, indent=2)

                        # Update state
                        ss["credit_active_model"] = resp["model_path"]
                        ss["credit_active_meta"] = meta
                        ss["credit_models"] = ss.get("credit_models", [])
                        ss["credit_models"].append(resp["model_path"])

                        st.success(f"""
                        âœ… **Retraining Complete**
                        â€¢ Model: `{resp['model_name']}`
                        â€¢ Accuracy: {resp['metrics']['accuracy']:.3f}
                        â€¢ ROC-AUC: {resp['metrics']['roc_auc']:.3f}
                        â€¢ Features: {', '.join(resp['feature_names'])}
                        """)

                        st.session_state["credit_model_dropdown"] = resp["model_name"]
                        st.session_state["credit_production_model"] = resp["model_path"]

                        # Auto-refresh UI
                        time.sleep(1.5)
                        st.rerun()
                    else:
                        st.error("âŒ Retrain failed or no model_path in response.")
                    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                except Exception as e:
                    st.error(f"Train failed: {e}")

        with colB:
            if st.button("â¬†ï¸ Promote last candidate to PRODUCTION"):
                try:
                    r = requests.post(f"{API_URL}/v1/training/promote", timeout=30)
                    st.write(r.json() if r.ok else r.text)
                except Exception as e:
                    st.error(f"Promote failed: {e}")

        st.markdown("---")
        st.markdown("#### Production Model")
        try:
            resp = requests.get(f"{API_URL}/v1/training/production_meta", timeout=5)
            if resp.ok:
                st.json(resp.json())
            else:
                st.info("No production model yet.")
        except Exception as e:
            st.warning(f"Could not load production meta: {e}")

    
    
    # # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # # ğŸ” TAB 5 â€” Training (Feedback â†’ Retrain)
    # with tab_train:
    #     st.subheader("ğŸ” From Human Feedback CSV â†’ Train and Promote Trained Model to Production Model ")

    #     st.markdown("**Drag & drop** one or more review CSVs exported from the Human Review tab.")
    #     up_list = st.file_uploader("Upload feedback CSV(s)", type=["csv"], accept_multiple_files=True, key="train_feedback_uploader")

    #     staged_paths: List[str] = []
    #     if up_list:
    #         for up in up_list:
    #             # stage to tmp_feedback dir
    #             dest = os.path.join(TMP_FEEDBACK_DIR, up.name)
    #             with open(dest, "wb") as f:
    #                 f.write(up.getvalue())
    #             staged_paths.append(dest)
    #         st.success(f"Staged {len(staged_paths)} feedback file(s) to {TMP_FEEDBACK_DIR}")
    #         st.write(staged_paths)

    #     st.markdown("#### Launch Retrain")
    #     payload = {
    #         "feedback_csvs": staged_paths,
    #         "user_name": st.session_state["user_info"]["name"],
    #         "agent_name": "credit_appraisal",
    #         "algo_name": "credit_lr",
    #     }
    #     st.code(json.dumps(payload, indent=2), language="json")

    #     colA, colB = st.columns([1,1])
    #     with colA:
    #         if st.button("ğŸš€ Train candidate model"):
    #             try:
    #                 r = requests.post(f"{API_URL}/v1/training/train", json=payload, timeout=90)
    #                 if r.ok:
    #                     st.success(r.json())
    #                     st.session_state["last_train_job"] = r.json().get("job_id")
    #                 else:
    #                     st.error(r.text)
    #             except Exception as e:
    #                 st.error(f"Train failed: {e}")
    #     with colB:
    #         if st.button("â¬†ï¸ Promote last candidate to PRODUCTION"):
    #             try:
    #                 r = requests.post(f"{API_URL}/v1/training/promote", timeout=30)
    #                 st.write(r.json() if r.ok else r.text)
    #             except Exception as e:
    #                 st.error(f"Promote failed: {e}")

    #     st.markdown("---")
    #     st.markdown("#### Production Model")
    #     try:
    #         resp = requests.get(f"{API_URL}/v1/training/production_meta", timeout=5)
    #         if resp.ok:
    #             st.json(resp.json())
    #         else:
    #             st.info("No production model yet.")
    #     except Exception as e:
    #         st.warning(f"Could not load production meta: {e}")




        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ” Loopback Section â€” Go back to Step 3
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("---")
        st.markdown("### ğŸ’³ Loop back to Step 3 â€” Credit Appraisal Agent")
        st.caption("After retraining, return to the Credit Appraisal tab and use your new production model.")

        st.markdown("""
        <a href="#credit-appraisal-stage" target="_self">
            <button style="
                background-color:#2563eb;
                color:white;
                border:none;
                border-radius:8px;
                padding:12px 24px;
                font-size:16px;
                font-weight:600;
                cursor:pointer;
                width:100%;
                box-shadow:0px 0px 6px rgba(37,99,235,0.5);
            ">â¬…ï¸ Go Back to Step 3 and Use New Model</button>
        </a>
        """, unsafe_allow_html=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ—£ï¸ TAB 6 â€” Feedback & Feature Requests
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab_feedback:
        st.subheader("ğŸ—£ï¸ Share Your Feedback and Feature Ideas")

        FEEDBACK_FILE = os.path.join(BASE_DIR, "agents_feedback.json")

        def load_feedback() -> dict:
            try:
                with open(FEEDBACK_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception:
                return {}

        def save_feedback(data: dict):
            try:
                with open(FEEDBACK_FILE, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            except Exception as e:
                st.error(f"Could not save feedback: {e}")

        feedback_data = load_feedback()

        # View all current agent feedback
        st.markdown("### ğŸ’¬ Current Agent Reviews & Ratings")
        for agent, fb in feedback_data.items():
            with st.expander(f"â­ {agent} â€” {fb.get('rating', 0)}/5  |  ğŸ‘¥ {fb.get('users', 0)} users"):
                st.markdown("#### Recent Comments:")
                for cmt in reversed(fb.get("comments", [])):
                    st.markdown(f"- {cmt}")
                st.markdown("---")

        st.markdown("### âœï¸ Submit Your Own Feedback or Feature Request")

        agent_choice = st.selectbox("Select Agent", list(feedback_data.keys()))
        new_comment = st.text_area("Your Comment or Feature Suggestion", placeholder="e.g. Add multi-language support for reports...")
        new_rating = st.slider("Your Rating", 1, 5, 5)


        if st.button("ğŸ“¨ Submit Feedback"):
            if new_comment.strip():
                fb = feedback_data.get(agent_choice, {"rating": 0, "users": 0, "comments": []})
                fb["comments"].append(new_comment.strip())
                fb["rating"] = round((fb.get("rating", 0) + new_rating) / 2, 2)
                fb["users"] = fb.get("users", 0) + 1
                feedback_data[agent_choice] = fb
                save_feedback(feedback_data)

                # âœ… Sync latest feedback globally
                st.session_state["feedback_data"] = feedback_data

                # âœ… Force full reload so Landing updates instantly
                st.success("âœ… Feedback submitted successfully!")
                st.rerun()
            else:
                st.warning("Please enter a comment before submitting.")


